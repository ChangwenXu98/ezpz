---
# sidebar: false
title: "`ezpz` üçã"
lightbox: true
# callout-appearance: simple
title-block-banner: false
citeproc: true
citation:
   author: Sam Foreman
   type: webpage
   title: "`ezpz`"
   url: https://saforem2.github.io/ezpz
editor:
   render-on-save: true
execute:
   freeze: auto
twitter-card:
    image: "./assets/thumbnail.png"
    creator: "@saforem2"
    site: "@saforem2"
open-graph:
    image: "./assets/thumbnail.png"
format:
  html: default
  gfm:
    author: Sam Foreman
    output-file: "README.md"
---

<!-- [![Pytorch](https://img.shields.io/badge/PyTorch-222222?logo=pytorch&logoColor=white)](#pytorch) [![Tensorflow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?&logo=TensorFlow&logoColor=white)](#tensorflow) [![hydra](https://img.shields.io/badge/Config-Hydra-89b8cd)](https://hydra.cc) -->

<!--
> [!NOTE]
> This library is **very much** still a WIP
> Any ideas / issues / suggestions for improving things would be greatly appreciated.
-->

## Overview

<!-- ::: {.callout-tip icon=false aria-title="Now Playing" title='[![](https://api.iconify.design/logos:spotify-icon.svg?color=%23888888) Now Playing:]{style="color:#1ED760;"}' collapse="true" style='width:100%; border: none!important; border-left: 1.5px solid #1ED760!important; border-radius: 0pt!important; opacity: 100%;'} -->

<!-- ::: {.callout-tip icon="false" collapse="false" style='width:100%; background-color: rgba(28, 28, 28, 0.0)!important; border-color: var(--bg-border)!important;' } -->

::: {.callout-tip icon=false title="<code>ezpz</code> üçã" collapse=false style="text-align: left!important; width:100%; background-color: var(--code-bg); border:none!important; border-left: 2px solid #1ED760!important; opacity:100%; border-radius: 0pt!important; margin-bottom: 0em; padding-bottom: 0.0rem;"}

Launch and train across all your accelerators, using your favorite framework +
backend combo.

`ezpz` simplifies the process of:

- <details><summary>Setting up + launching distributed training:</summary>

    - <details closed><summary><code>import ezpz as ez</code></summary>

        - `RANK = `
          [`ez.setup_torch(backend=backend)`](https://github.com/saforem2/ezpz/blob/main/src/ezpz/dist.py#L551)
          [for `backend` $\in$ \{`DDP`, `deepspeed`, `horovod`}]{.dim-text}

        - `RANK =`
          [`ez.get_rank()`](https://github.com/saforem2/ezpz/blob/main/src/ezpz/dist.py#396)

        - `LOCAL_RANK =`
          [`ez.get_local_rank()`](https://github.com/saforem2/ezpz/blob/main/src/ezpz/dist.py#448)

        - `WORLD_SIZE =`
          [`ez.get_world_size()`](https://github.com/saforem2/ezpz/blob/main/src/ezpz/dist.py#L417)

      [(see [`ezpz/dist.py`](https://github.com/saforem2/ezpz/blob/main/src/ezpz/dist.py) for more details).]{.dim-text}

    </details>


</details>

- <details closed><summary>Using your favorite `{framework, backend}`</summary>

  On any accelerator:

  - [`framework=pytorch`](#pytorch) + `backend={DDP, deepspeed, horovod}`

  - [`framework=tensorflow`](#tensorflow) + `backend=horovod`

  - [`ez.get_torch_device()`](https://github.com/saforem2/ezpz/blob/main/src/ezpz/dist.py#L332): {`cuda`, `xpu`, `mps`, `cpu`}

  - [`ez.get_torch_backend()`](https://github.com/saforem2/ezpz/blob/main/src/ezpz/dist.py#L348): {`nccl`, `ccl`, `gloo`}

  _2ez_ üòé. (see [frameworks](#frameworks) for additional details)

</details>

- <details closed><summary>Writing device agnostic code:</summary>

  <details closed><summary><code>ezpz_data_parallel.py</code></summary>

  ```python
  """
  ezpz_ddp.py

  - to launch:

    $ source ezpz/src/ezpz/bin/savejobenv
    $ BACKEND=DDP launch python3 ezpz_ddp.py
  """
  import os
  import logging
  import torch
  import ezpz as ez

  # backend can be any of DDP, deespepeed, horovod
  RANK = ez.setup_torch(
      backend=(
          backend := os.environ.get('BACKEND', 'DDP')
      )
  )
  WORLD_SIZE = ez.get_world_size()
  DEVICE = ez.get_device()

  # log only from RANK == 0
  logger = logging.getLogger(__name__)
  logger.setLevel("INFO") if RANK == 0 else logger.setLevel("CRITICAL")

  model = torch.nn.Linear(3, 4)
  model.to(DEVICE)
  optimizer = torch.optim.Adam(model.parameters())
  if WORLD_SIZE > 1:
      if backend.lower() == 'ddp':
          from torch.nn.parallel import DistributedDataParallel as DDP
          model = DDP(model)
      elif backend.lower() in ('ds', 'deepspeed'):
          import deepspeed
          model, optimizer, *_ = deepspeed.initialize(
              model=model,
              optimizer=optimizer
          )

  x = torch.tensor([1.0, 2.0, 3.0]).to(DEVICE)
  y = model(x)
  loss = y.sum()
  if backend == 'deepspeed':
      model.backward(loss)
      model.step(loss)
  else:
      loss = loss.backward()
      optimizer.step()
  ```

  <details closed><summary>Output:</summary>

    <details closed><summary><code>XPU</code></summary>

    ```bash
    [04:50:57 PM] [foremans@x1921c0s0b0n0] ~/q/llm.devkit/Megatron-DeepSpeed/dep/ezpz/s/ezpz Ôêò main q4-drop 32s
    $ launch python3 -Wignore test_dist.py
    Connected to tcp://x1921c0s0b0n0.hostmgmt2000.cm.americas.sgi.com:7919
    Found executable /home/foremans/miniconda3/envs/q4-drop/bin/python3
    Launching application 5bf3e9e8-89fb-412a-a49e-3c81601436b7
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=9/23][local_rank=9/11][node=1/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=14/23][local_rank=2/11][node=0/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=3/23][local_rank=3/11][node=1/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=17/23][local_rank=5/11][node=1/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=6/23][local_rank=6/11][node=0/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=13/23][local_rank=1/11][node=1/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=7/23][local_rank=7/11][node=1/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=19/23][local_rank=7/11][node=1/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=8/23][local_rank=8/11][node=0/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=21/23][local_rank=9/11][node=1/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=10/23][local_rank=10/11][node=0/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=22/23][local_rank=10/11][node=0/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=11/23][local_rank=11/11][node=1/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=23/23][local_rank=11/11][node=1/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=2/23][local_rank=2/11][node=0/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=20/23][local_rank=8/11][node=0/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=4/23][local_rank=4/11][node=0/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=15/23][local_rank=3/11][node=1/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=18/23][local_rank=6/11][node=0/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=12/23][local_rank=0/11][node=0/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=1/23][local_rank=1/11][node=1/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=16/23][local_rank=4/11][node=0/1]
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=5/23][local_rank=5/11][node=1/1]
    [2024-04-19 16:51:06][INFO][dist:239] - DistInfo={
        "DEVICE": "xpu",
        "DEVICE_ID": "xpu:0",
        "DISTRIBUTED_BACKEND": "ccl",
        "GPUS_PER_NODE": 12,
        "HOSTFILE": "/var/spool/pbs/aux/8992337.amn-0001",
        "HOSTNAME": "x1921c0s0b0n0.hostmgmt2000.cm.americas.sgi.com",
        "HOSTS": "['x1921c0s0b0n0', 'x1921c0s5b0n0']",
        "LOCAL_RANK": 0,
        "MACHINE": "SunSpot",
        "NGPUS": 24,
        "NODE_ID": 0,
        "NUM_NODES": 2,
        "RANK": 0,
        "SCHEDULER": "PBS",
        "WORLD_SIZE_IN_USE": 24,
        "WORLD_SIZE_TOTAL": 24
    }
    [2024-04-19 16:51:06][INFO][dist:602] - Using oneccl_bindings from: /lus/gila/projects/Aurora_deployment/foremans/q4-drop_sunspot/llm.devkit/torch-ccl/oneccl_bindings_for_pytorch/__init__.py
    [2024-04-19 16:51:06][INFO][dist:604] - Using ipex from: /home/foremans/miniconda3/envs/q4-drop/lib/python3.9/site-packages/intel_extension_for_pytorch/__init__.py
    [2024-04-19 16:51:06][INFO][dist:605] - [0/24] Using device='xpu' with backend='DDP' + 'ccl' for distributed training.
    [2024-04-19 16:51:06][INFO][dist:290] - [device='xpu'][rank=0/23][local_rank=0/11][node=0/1]
    [2024-04-19 16:51:06][WARNING][dist:296] - Using [24 / 24] available "xpu" devices !!
    2024:04:19-16:51:06:(16909) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
    2024:04:19-16:51:06:(16910) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
    2024:04:19-16:51:06:(16912) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
    2024:04:19-16:51:06:(16913) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
    2024:04:19-16:51:06:(16914) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
    2024:04:19-16:51:06:(16915) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
    2024:04:19-16:51:06:(16916) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
    2024:04:19-16:51:06:(16917) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
    2024:04:19-16:51:06:(16918) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
    2024:04:19-16:51:06:(16919) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
    2024:04:19-16:51:06:(16920) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
    2024:04:19-16:51:06:(16921) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
    [2024-04-19 16:51:06][INFO][test_dist:71] - model=Network(
      (layers): Sequential(
        (0): Linear(in_features=128, out_features=1024, bias=True)
        (1): Linear(in_features=1024, out_features=512, bias=True)
        (2): Linear(in_features=512, out_features=256, bias=True)
        (3): Linear(in_features=256, out_features=128, bias=True)
        (4): Linear(in_features=128, out_features=128, bias=True)
      )
    )
    [2024-04-19 16:51:18][INFO][test_dist:101] - iter=0, loss=2709.53418, dt=1.380, dtf=0.950, dtb=0.430
    [2024-04-19 16:51:18][INFO][test_dist:101] - iter=1, loss=2058.49805, dt=0.133, dtf=0.002, dtb=0.131
    [2024-04-19 16:51:18][INFO][test_dist:101] - iter=2, loss=1507.91187, dt=0.004, dtf=0.001, dtb=0.004
    [2024-04-19 16:51:18][INFO][test_dist:101] - iter=3, loss=1181.78577, dt=0.004, dtf=0.001, dtb=0.003
    [2024-04-19 16:51:18][INFO][test_dist:101] - iter=4, loss=949.43561, dt=0.004, dtf=0.001, dtb=0.003
    [2024-04-19 16:51:18][INFO][test_dist:101] - iter=5, loss=848.14905, dt=0.004, dtf=0.001, dtb=0.003
    [2024-04-19 16:51:18][INFO][test_dist:101] - iter=6, loss=788.76123, dt=0.004, dtf=0.001, dtb=0.003
    [2024-04-19 16:51:18][INFO][test_dist:101] - iter=7, loss=753.59509, dt=0.004, dtf=0.001, dtb=0.003
    [2024-04-19 16:51:18][INFO][test_dist:101] - iter=8, loss=750.62225, dt=0.004, dtf=0.001, dtb=0.003
    [2024-04-19 16:51:18][INFO][test_dist:101] - iter=9, loss=740.23474, dt=0.004, dtf=0.001, dtb=0.003
    Application 5bf3e9e8 resources: utime=621s stime=111s maxrss=1746816KB inblock=192 oublock=16 minflt=10719359 majflt=7493 nvcsw=169332 nivcsw=77546
    ```

    </details>

    <details closed><summary><code>CPU</code></summary>

    ```bash
    2023-11-11 $ TORCH_DEVICE=cpu mpirun -np 12 python3 test_dist.py
    [2024-04-19 14:44:12][INFO][dist:290] - [device='cpu'][rank=1/11][local_rank=1/11][node=0/0]
    [2024-04-19 14:44:12][INFO][dist:290] - [device='cpu'][rank=3/11][local_rank=3/11][node=0/0]
    [2024-04-19 14:44:12][INFO][dist:290] - [device='cpu'][rank=6/11][local_rank=6/11][node=0/0]
    [2024-04-19 14:44:12][INFO][dist:290] - [device='cpu'][rank=5/11][local_rank=5/11][node=0/0]
    [2024-04-19 14:44:12][INFO][dist:290] - [device='cpu'][rank=2/11][local_rank=2/11][node=0/0]
    [2024-04-19 14:44:12][INFO][dist:290] - [device='cpu'][rank=10/11][local_rank=10/11][node=0/0]
    [2024-04-19 14:44:12][INFO][dist:290] - [device='cpu'][rank=4/11][local_rank=4/11][node=0/0]
    [2024-04-19 14:44:12][INFO][dist:290] - [device='cpu'][rank=7/11][local_rank=7/11][node=0/0]
    [2024-04-19 14:44:12][INFO][dist:290] - [device='cpu'][rank=9/11][local_rank=9/11][node=0/0]
    [2024-04-19 14:44:13][INFO][dist:290] - [device='cpu'][rank=11/11][local_rank=11/11][node=0/0]
    [2024-04-19 14:44:13][INFO][dist:290] - [device='cpu'][rank=8/11][local_rank=8/11][node=0/0]
    [2024-04-19 14:44:13][INFO][dist:239] - DistInfo={
        "DEVICE": "cpu",
        "DEVICE_ID": "cpu:0",
        "DISTRIBUTED_BACKEND": "gloo",
        "GPUS_PER_NODE": 12,
        "HOSTFILE": "/Users/samforeman/projects/saforem2/ezpz/src/ezpz/hostfile",
        "HOSTNAME": "Sams-MacBook-Pro.local",
        "HOSTS": "['Sams-MacBook-Pro']",
        "LOCAL_RANK": 0,
        "MACHINE": "Sams-MacBook-Pro.local",
        "NGPUS": 12,
        "NODE_ID": 0,
        "NUM_NODES": 1,
        "RANK": 0,
        "SCHEDULER": "LOCAL",
        "WORLD_SIZE_IN_USE": 12,
        "WORLD_SIZE_TOTAL": 12
    }
    [2024-04-19 14:44:13][INFO][dist:605] - [0/12] Using device='cpu' with backend='DDP' + 'gloo' for distributed training.
    [2024-04-19 14:44:13][INFO][dist:290] - [device='cpu'][rank=0/11][local_rank=0/11][node=0/0]
    [2024-04-19 14:44:13][WARNING][dist:296] - Using [12 / 12] available "cpu" devices !!
    [2024-04-19 14:44:13][INFO][test_dist:72] - model=Network(
      (layers): Sequential(
        (0): Linear(in_features=128, out_features=1024, bias=True)
        (1): Linear(in_features=1024, out_features=512, bias=True)
        (2): Linear(in_features=512, out_features=256, bias=True)
        (3): Linear(in_features=256, out_features=128, bias=True)
        (4): Linear(in_features=128, out_features=128, bias=True)
      )
    )
    [2024-04-19 14:44:14][INFO][test_dist:102] - iter=0, loss=2801.62549, dt=0.389, dtf=0.042, dtb=0.348
    [2024-04-19 14:44:14][INFO][test_dist:102] - iter=1, loss=2092.84692, dt=0.051, dtf=0.010, dtb=0.041
    [2024-04-19 14:44:14][INFO][test_dist:102] - iter=2, loss=1482.45520, dt=0.037, dtf=0.004, dtb=0.033
    [2024-04-19 14:44:14][INFO][test_dist:102] - iter=3, loss=1174.38037, dt=0.033, dtf=0.002, dtb=0.031
    [2024-04-19 14:44:14][INFO][test_dist:102] - iter=4, loss=938.39917, dt=0.032, dtf=0.003, dtb=0.030
    [2024-04-19 14:44:14][INFO][test_dist:102] - iter=5, loss=888.37390, dt=0.035, dtf=0.001, dtb=0.033
    [2024-04-19 14:44:14][INFO][test_dist:102] - iter=6, loss=784.63470, dt=0.036, dtf=0.003, dtb=0.032
    [2024-04-19 14:44:14][INFO][test_dist:102] - iter=7, loss=749.53839, dt=0.033, dtf=0.002, dtb=0.031
    [2024-04-19 14:44:14][INFO][test_dist:102] - iter=8, loss=732.22656, dt=0.036, dtf=0.003, dtb=0.034
    [2024-04-19 14:44:15][INFO][test_dist:102] - iter=9, loss=730.63776, dt=0.034, dtf=0.001, dtb=0.033
    35.68s user 17.20s system 546% cpu 9.681s total
    ```

    </details>

  </details>

  </details>

- <details closed><summary>Using <code>wandb</code>:</summary>

    - `ez.setup_wandb(project_name='ezpz')`

  </details>

- **Full support** for any {`device` + `framework` + `backend`}:
    - device: {`GPU`, `XPU`, `MPS`, `CPU`}
    - framework: {`torch`, `deepspeed`, `horovod`, `tensorflow`}
    - backend: {`DDP`, `deepspeed`, `horovod`}

:::


## Setup + `launch`

`ezpz` setup on any of `{thetaGPU, Polaris, Perlmutter}`:

1. `git` clone + `pip` install:

    ```bash
    git clone 'https://github.com/saforem2/ezpz'
    python3 -m pip install -e ezpz
    ```

1. Save Job info + define `launch` alias:

    ```bash
    $ source ezpz/src/ezpz/bin/savejobenv
    ```

    <details closed><summary><code>output</code></summary>

    ```bash
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚îÇ [Hosts]:
    ‚îÇ     ‚Ä¢ x4415c6s5b0n0, x4415c6s6b0n0, x4415c6s7b0n0, x4415c7s0b0n0
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚îÇ [DIST INFO]:
    ‚îÇ     ‚Ä¢ Loading job env from: /home/foremans/.pbsenv
    ‚îÇ     ‚Ä¢ HOSTFILE: /var/spool/pbs/aux/297306.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov
    ‚îÇ     ‚Ä¢ NHOSTS: 4
    ‚îÇ     ‚Ä¢ NGPU_PER_HOST: 12
    ‚îÇ     ‚Ä¢ NGPUS (NHOSTS x NGPU_PER_HOST): 48
    ‚îÇ     ‚Ä¢ DIST_LAUNCH: mpiexec --verbose --envall -n 48 -ppn 12 --hostfile /var/spool/pbs/aux/297306.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov
    ‚îÇ     ‚Ä¢ Defining alias: launch: aliased to mpiexec --verbose --envall -n 48 -ppn 12 --hostfile /var/spool/pbs/aux/297306.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ```

    </details>

1. `launch` [`__main__.py`](./src/ezpz/__main__.py) with `pytorch` + `deepspeed`:

    ```bash
    $ launch python3 -m ezpz framework=pytorch backend=deepspeed
    ```

    <details closed><summary><code>output</code></summary>

    ```bash
    $ launch python3 -m ezpz framework=pytorch backend=DDP
    [2023-12-19 13:33:24][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:24][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:24][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:24][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:24][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:24][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:24][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:24][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:24][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:24][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:24][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:24][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:24][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:24][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:25][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:26][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:26][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:26][INFO][dist.py:243] - Using DDP for distributed training
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:26][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:27][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:27][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:27][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:27][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:27][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:27][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:27][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:27][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:27][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:27][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:27][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:27][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:27][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:28][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:28][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:29][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:29][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:29][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:30][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:30][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:30][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:30][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:30][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:30][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:34][INFO][dist.py:292] - Using device='xpu'
    [2023-12-19 13:33:35][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:35][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:35][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:35][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:35][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:35][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:35][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:35][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:35][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:35][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:35][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:35][WARNING][dist.py:104] - Using backend='ccl'
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 1 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 2 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 3 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 4 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 0 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 5 / 47
    [2023-12-19 13:33:35][INFO][__main__.py:49] - {
        "_target_": "ezpz.configs.TrainConfig",
        "framework": "pytorch",
        "backend": "DDP",
        "ds_config_path": null,
        "port": null,
        "seed": null,
        "use_wandb": true,
        "wandb_project_name": null,
        "precision": null,
        "ngpus": null
    }
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 9 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 10 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 11 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 7 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 8 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 6 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 12 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 13 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 14 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 15 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 18 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 19 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 20 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 21 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 22 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 23 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 24 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 25 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 26 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 27 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 30 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 16 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 17 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 28 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 32 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 33 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 36 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 37 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 38 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 39 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 43 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 46 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 29 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 47 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 31 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 34 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 35 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 42 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 41 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 44 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 45 / 47
    [2023-12-19 13:33:35][INFO][dist.py:307] - RANK: 40 / 47
    [2023-12-19 13:33:47][INFO][dist.py:415] - Setting up wandb from rank: 0
    [2023-12-19 13:33:47][INFO][dist.py:416] - Using: WB PROJECT: ezpz
    [2023-12-19 13:33:58][INFO][dist.py:448] - W&B RUN: [flowing-wood-8](https://wandb.ai/l2hmc-qcd/ezpz/runs/uya29gm5)
    [2023-12-19 13:33:58][INFO][dist.py:490] - Running on x4415c6s5b0n0.hostmgmt2415.cm.aurora.alcf.anl.gov
    [2023-12-19 13:33:58][INFO][dist.py:506] - Reading hosts from /var/spool/pbs/aux/297306.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov
    [2023-12-19 13:33:58][INFO][__main__.py:57] - Output dir: /lus/gecko/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/src/ezpz/outputs/runs/pytorch/DDP/2023-12-19/13-33-17
    [2023-12-19 13:33:58][CRITICAL][dist.py:519] - üöÄ flowing-wood-8
    [2023-12-19 13:33:58][CRITICAL][dist.py:520] - üîó https://wandb.ai/l2hmc-qcd/ezpz/runs/uya29gm5
    [2023-12-19 13:33:58][CRITICAL][dist.py:521] - üìÇ/: /lus/gecko/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/src/ezpz/outputs/runs/pytorch/DDP/2023-12-19/13-33-17/wandb/run-20231219_133354-uya29gm5/files
    [2023-12-19 13:33:58][INFO][dist.py:563] - Adding /lus/gecko/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/src/ezpz/ezpz-pt-DDP-xpu.log to W&B artifact...
    [2023-12-19 13:33:58][INFO][dist.py:563] - Adding /lus/gecko/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/src/ezpz/outputs/runs/pytorch/DDP/2023-12-19/13-33-17/__main__.log to W&B artifact...
    [2023-12-19 13:33:58][INFO][dist.py:563] - Adding /lus/gecko/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/src/ezpz/outputs/runs/pytorch/DDP/2023-12-19/13-33-17/main_debug.log to W&B artifact...
    [2023-12-19 13:33:58][INFO][dist.py:563] - Adding /lus/gecko/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/src/ezpz/outputs/runs/pytorch/DDP/2023-12-19/13-33-16/__main__.log to W&B artifact...
    ```

    </details>

</details>


### Tested Machines

<details closed><summary><b>Aurora</b> (@ ALCF)</summary>

```bash
# launch job
$ qsub -q EarlyAppAccess -A Aurora_Deployment -l walltime=2:00:00 -l select=4 -I

# load frameworks
$ module use -a /soft/modulefiles ; module --ignore_cache load frameworks
$ module load frameworks/.2023.12.15.001

# install `ezpz`
$ git clone https://github.com/saforem2/ezpz
$ cd ezpz
$ mkdir -p venvs/aurora/2023.12.15.001
$ python3 -m venv venvs/aurora/2023.12.15.001 --system-site-packages
$ source venvs/aurora/2023.12.15.001/bin/activate
$ python3 -m pip install -e .

# print job info and define `launch` alias
$ source ezpz/src/ezpz/bin/savejobenv
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îÇ [Hosts]:
‚îÇ     ‚Ä¢ x4415c6s5b0n0.hostmgmt2415.cm.aurora.alcf.anl.gov
x4415c6s6b0n0.hostmgmt2415.cm.aurora.alcf.anl.gov
x4415c6s7b0n0.hostmgmt2415.cm.aurora.alcf.anl.gov
x4415c7s0b0n0.hostmgmt2415.cm.aurora.alcf.anl.gov
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îÇ [DIST INFO]:
‚îÇ     ‚Ä¢ Loading job env from: /home/foremans/.pbsenv
‚îÇ     ‚Ä¢ HOSTFILE: /var/spool/pbs/aux/297306.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov
‚îÇ     ‚Ä¢ NHOSTS: 4
‚îÇ     ‚Ä¢ NGPU_PER_HOST: 12
‚îÇ     ‚Ä¢ NGPUS (NHOSTS x NGPU_PER_HOST): 48
‚îÇ     ‚Ä¢ DIST_LAUNCH: mpiexec --verbose --envall -n 48 -ppn 12 --hostfile /var/spool/pbs/aux/297306.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov
‚îÇ     ‚Ä¢ Defining alias: launch: aliased to mpiexec --verbose --envall -n 48 -ppn 12 --hostfile /var/spool/pbs/aux/297306.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
```

</details>

<details closed><summary><b>Polaris</b> (@ ALCF)</summary>

```bash
# Most recent `conda` versions as of 10-17-2023
if [[ $(hostname) == x3* ]]; then
    export MACHINE="polaris"
    export CONDA_DATE="2023-10-04"
elif [[ $(hostname) == theta* ]]; then
    export MACHINE="thetaGPU"
    export CONDA_DATE="2023-01-11"
else
    echo "Unknown hostname $(hostname)"
fi
module load "conda/${CONDA_DATE}" ; conda activate base
# Clone saforem2/ezpz and navigate into it
git clone https://github.com/saforem2/ezpz
cd ezpz
# Make a new venv for this project,
# in the project root: ./venvs/$MACHINE/$CONDA_DATE
VENV_DIR="venvs/${MACHINE}/${CONDA_DATE}"
python3 -m venv "${VENV_DIR}" --system-site-packages
source "venvs/${MACHINE}/${CONDA_DATE}/bin/activate"
# install `ezpz` into this `venv`
python3 -m pip install -e .
# to launch simple training example
# (launches `src/ezpz/__main__.py`)
cd src/ezpz
./bin/train.sh framework=pytorch backend=DDP
```

</details>

<details closed><summary><b>Perlmutter</b> (@ NERSC):</summary>

```bash
# request slurm allocation with `salloc`
$ NODES=2 ; HRS=2 ; salloc --nodes $NODES --qos preempt --time $HRS:00:00 -C 'gpu&hbm80g' --gpus=$(( 4 * NODES )) -A <proj>_g
# load `pytorch/2.0.1` module
$ module load libfabric cudatoolkit pytorch/2.0.1
# Clone saforem2/ezpz and navigate into it
$ git clone https://github.com/saforem2/ezpz
$ cd ezpz
# update pip and install `ezpz`
$ python3 -m pip install --upgrade pip setuptools wheel
$ python3 -m pip install -e .
$ cd src/ezpz
$ ./bin/train.sh framework=pytorch backend=DDP
```

where `framework` $\in$ `{pytorch, tensorflow}`, and `backend` $\in$ `{DDP, deepspeed,
horovod}`[^tf-hvd]  


</details>

[^tf-hvd]: Note `framework=tensorflow` is **only** compatible with `backend=horovod`

## Details


We can `launch` on any of `{ThetaGPU, Polaris, Perlmutter}`$\left(^{\ast}\right)$ 
with a specific `{framework, backend}` combo by

1. [`savejobenv`](./src/ezpz/bin/savejobenv):

    ```bash
    $ source src/ezpz/bin/savejobenv
    ```

    - This will `export launch=<launcher> <launcher-opts>`
      for `<launcher>` $\in$ `{mpirun,mpiexec,srun}`
      on $(^{\ast})$ respectively.

    - By default, `launch <exec>` will launch `<exec>` across
      _all_ the available GPUs in your active `{COBALT,PBS,slurm}` job.

2. `launch`

    ```bash
    $ launch $(which python3) -m ezpz framework=<framework> backend=<backend>
    ```

    - Will `launch` [`__main__.py`](./src/ezpz/__main__.py) (in this case) with framework
    `<framework>` and backend `<backend>` (e.g. `pytorch` and `deepspeed`)


### Complete Example

```bash
#!/bin/bash --login
git clone https://github.com/saforem2/ezpz
./ezpz/src/ezpz/bin/savejobenv
launch $(which python3) -m ezpz framework=<framework> backend=<backend>
```

for `framework` $\in$ `{pytorch, tensorflow}` and `backend` $\in$ `{horovod, deepspeed, DDP}`[^1]

[^1]: `deepspeed`, `DDP` only support `pytorch`


## Frameworks

<!-- <details closed><summary>PyTorch</summary> -->

### PyTorch

<details closed><summary><code>DDP</code>:</summary>

```bash
launch framework=pytorch backend=DDP
```

<details closed><summary><b>Output:</b></summary>

```bash
Connected to tcp://x3005c0s31b1n0.hsn.cm.polaris.alcf.anl.gov:7919
Found executable /soft/datascience/conda/2023-10-04/mconda3/bin/python3
Launching application c079ffa9-4732-45ba-995b-e5685330311b
[10/05/23 16:56:26][INFO][dist.py:362] - Using DDP for distributed training
[10/05/23 16:56:27][INFO][dist.py:413] - RANK: 0 / 7
[10/05/23 16:56:27][INFO][dist.py:413] - RANK: 2 / 7
[10/05/23 16:56:27][INFO][dist.py:413] - RANK: 4 / 7
[10/05/23 16:56:27][INFO][dist.py:413] - RANK: 3 / 7
[10/05/23 16:56:27][INFO][dist.py:413] - RANK: 1 / 7
[10/05/23 16:56:27][INFO][dist.py:413] - RANK: 6 / 7
[10/05/23 16:56:27][INFO][dist.py:413] - RANK: 5 / 7
[10/05/23 16:56:27][INFO][dist.py:413] - RANK: 7 / 7
```

</details>

</details>

<details closed><summary><b><code>deepspeed</code>:</b></summary>

```bash
launch framework=pytorch backend=deepspeed
```

<details closed><summary><b>Output:</b></summary>

```bash
Connected to tcp://x3005c0s31b1n0.hsn.cm.polaris.alcf.anl.gov:7919
Found executable /soft/datascience/conda/2023-10-04/mconda3/bin/python3
Launching application c1c5bcd5-c300-4927-82e4-236d4643e31d
[10/05/23 16:56:34][INFO][dist.py:362] - Using deepspeed for distributed training
[2023-10-05 16:56:34,949] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-05 16:56:34,949] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-05 16:56:34,949] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-05 16:56:34,949] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-05 16:56:34,953] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-05 16:56:34,953] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-05 16:56:34,953] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-05 16:56:34,953] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-10-05 16:56:40,160] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-10-05 16:56:40,160] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-10-05 16:56:40,160] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-10-05 16:56:40,160] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-10-05 16:56:40,160] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-10-05 16:56:40,160] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-10-05 16:56:40,160] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-10-05 16:56:40,160] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-10-05 16:56:40,767] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-10-05 16:56:40,767] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-10-05 16:56:40,767] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-10-05 16:56:40,767] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-10-05 16:56:40,767] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-10-05 16:56:40,767] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-10-05 16:56:40,767] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-10-05 16:56:40,767] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-10-05 16:56:41,621] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=4, local_rank=0, world_size=8, master_addr=10.140.57.89, master_port=29500
[2023-10-05 16:56:41,621] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=5, local_rank=1, world_size=8, master_addr=10.140.57.89, master_port=29500
[2023-10-05 16:56:41,621] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=8, master_addr=10.140.57.89, master_port=29500
[2023-10-05 16:56:41,621] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=6, local_rank=2, world_size=8, master_addr=10.140.57.89, master_port=29500
[2023-10-05 16:56:41,621] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=1, local_rank=1, world_size=8, master_addr=10.140.57.89, master_port=29500
[2023-10-05 16:56:41,621] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=7, local_rank=3, world_size=8, master_addr=10.140.57.89, master_port=29500
[2023-10-05 16:56:41,621] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=2, local_rank=2, world_size=8, master_addr=10.140.57.89, master_port=29500
[2023-10-05 16:56:41,621] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=3, local_rank=3, world_size=8, master_addr=10.140.57.89, master_port=29500
[2023-10-05 16:56:41,621] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[10/05/23 16:56:41][INFO][dist.py:413] - RANK: 0 / 7
[10/05/23 16:56:41][INFO][dist.py:413] - RANK: 2 / 7
[10/05/23 16:56:41][INFO][dist.py:413] - RANK: 1 / 7
[10/05/23 16:56:41][INFO][dist.py:413] - RANK: 7 / 7
[10/05/23 16:56:41][INFO][dist.py:413] - RANK: 4 / 7
[10/05/23 16:56:41][INFO][dist.py:413] - RANK: 5 / 7
[10/05/23 16:56:41][INFO][dist.py:413] - RANK: 6 / 7
[10/05/23 16:56:41][INFO][dist.py:413] - RANK: 3 / 7
```

</details>

</details>

<details closed><summary><b><code>horovod</code></b></summary>

```bash
launch framework=pytorch backend=horovod
```

<details closed><summary><b>Output:</b></summary>

```bash
Connected to tcp://x3005c0s31b1n0.hsn.cm.polaris.alcf.anl.gov:7919
Found executable /soft/datascience/conda/2023-10-04/mconda3/bin/python3
Launching application c079ffa9-4732-45ba-995b-e5685330311b
[10/05/23 16:56:26][INFO][dist.py:362] - Using DDP for distributed training
[10/05/23 16:56:27][INFO][dist.py:413] - RANK: 0 / 7
[10/05/23 16:56:27][INFO][dist.py:413] - RANK: 2 / 7
[10/05/23 16:56:27][INFO][dist.py:413] - RANK: 4 / 7
[10/05/23 16:56:27][INFO][dist.py:413] - RANK: 3 / 7
[10/05/23 16:56:27][INFO][dist.py:413] - RANK: 1 / 7
[10/05/23 16:56:27][INFO][dist.py:413] - RANK: 6 / 7
[10/05/23 16:56:27][INFO][dist.py:413] - RANK: 5 / 7
[10/05/23 16:56:27][INFO][dist.py:413] - RANK: 7 / 7
```

</details>

</details>

</details>

### TensorFlow

<details closed><summary><b><code>horovod</b></code></summary>

```bash
launch framework=tensorflow backend=horovod
```

<details closed><summary><b>Output:</b></summary>

```bash
Connected to tcp://x3005c0s31b1n0.hsn.cm.polaris.alcf.anl.gov:7919
Found executable /soft/datascience/conda/2023-10-04/mconda3/bin/python3
Launching application 2b7b89f3-5f40-42de-aa12-a15876baee09
2023-10-05 16:56:49.870938: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-10-05 16:56:49.870938: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-10-05 16:56:49.870938: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-10-05 16:56:49.870940: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-10-05 16:56:50.038355: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-10-05 16:56:50.038355: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-10-05 16:56:50.038353: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-10-05 16:56:50.038359: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-10-05 16:57:00.277129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38341 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:07:00.0,compute capability: 8.0
[10/05/23 16:57:00][INFO][dist.py:203] - RANK: 4 / 7
2023-10-05 16:57:00.303774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38341 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:07:00.0,compute capability: 8.0
[10/05/23 16:57:00][INFO][dist.py:203] - RANK: 0 / 7
2023-10-05 16:57:00.430211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38341 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:46:00.0,compute capability: 8.0
[10/05/23 16:57:00][INFO][dist.py:203] - RANK: 5 / 7
2023-10-05 16:57:00.445891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38341 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:46:00.0,compute capability: 8.0
2023-10-05 16:57:00.447921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38341 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:85:00.0,compute capability: 8.0
[10/05/23 16:57:00][INFO][dist.py:203] - RANK: 1 / 7
[10/05/23 16:57:00][INFO][dist.py:203] - RANK: 2 / 7
2023-10-05 16:57:00.452035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38341 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:85:00.0,compute capability: 8.0
[10/05/23 16:57:00][INFO][dist.py:203] - RANK: 6 / 7
2023-10-05 16:57:00.458780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38341 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c7:00.0,compute capability: 8.0
[10/05/23 16:57:00][INFO][dist.py:203] - RANK: 7 / 7
2023-10-05 16:57:00.472986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38341 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c7:00.0,compute capability: 8.0
[10/05/23 16:57:00][INFO][dist.py:203] - RANK: 3 / 7
```

</details>

</details>

## Helper Utilities

- [`src/ezpz/bin/savejobenv`](./src/ezpz/bin/savejobenv): Shell script to save
  relevant job related environment variables to a file which can be `sourced`
  from new login instances.

    <details closed><summary><b><code>savejobenv</code></b></summary>

    Launch a job, clone (or navigate into) `ezpz`, and `source` [`src/ezpz/bin/savejobenv`](./src/ezpz/bin/savejobenv):

    ```bash
    (thetalogin4) $ qsub-gpu -A datascience -n 2 -q full-node --attrs="filesystems=home,grand,eagle,theta-fs0:ssds=required" -t 06:00 -I
    Job routed to queue "full-node".
    Wait for job 10155652 to start...
    Opening interactive session to thetagpu04
    [...]
    ```

    ```bash
    (thetagpu04) $ git clone https://github.com/saforem2/ezpz
    (thetagpu04) $ source ezpz/src/ezpz/bin/savejobenv
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚îÇ Writing COBALT vars to /home/foremans/.cobaltenv
    ‚îÇ HOSTFILE: /var/tmp/cobalt.10155652
    ‚îÇ NHOSTS: 2
    ‚îÇ 8 GPUs per host
    ‚îÇ 16 GPUs total
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚îÇ [DIST INFO]:
    ‚îÇ   ‚Ä¢ Writing Job info to /home/foremans/.cobaltenv
    ‚îÇ     ‚Ä¢ HOSTFILE: /var/tmp/cobalt.10155652
    ‚îÇ     ‚Ä¢ NHOSTS: 2
    ‚îÇ     ‚Ä¢ NGPU_PER_HOST: 8
    ‚îÇ     ‚Ä¢ NGPUS = (NHOSTS * NGPU_PER_HOST) = 16
    ‚îÇ [Hosts]:
    ‚îÇ       ‚Ä¢ thetagpu04 thetagpu19
    ‚îÇ [Launch]:
    ‚îÇ     ‚Ä¢ Use: 'launch' (=mpirun -n  -N  --hostfile /var/tmp/cobalt.10155652 -x PATH -x LD_LIBRARY_PATH)
    ‚îÇ       to launch job
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚îÇ YOU ARE HERE: /home/foremans
    ‚îÇ Run 'source ./bin/getjobenv' in a NEW SHELL to automatically set env vars
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ```

    </details>

- [`src/ezpz/bin/getjobenv`](./src/ezpz/bin/getjobenv): Shell script that, when
  sourced, will populate the current environment with the necessary job-related
  variables.

    <details closed><summary><b><code>getjobenv</code></b></summary>

    Now, in a **NEW SHELL**

    ```bash
    (localhost)   $ ssh <user>@theta
    ```

    ```bash
    (thetalogin4) $ ssh thetagpu19
    ```

    ```bash
    (thetagpu19)  $ module load conda/2023-01-11; conda activate base
    (thetagpu19)  $ cd ezpz
    (thetagpu19)  $ source ./src/ezpz/bin/getjobenv
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚îÇ [Hosts]: 
    ‚îÇ     ‚Ä¢ thetagpu04, thetagpu19
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚îÇ [DIST INFO]: 
    ‚îÇ     ‚Ä¢ Loading job env from: /home/foremans/.cobaltenv
    ‚îÇ     ‚Ä¢ HOSTFILE: /var/tmp/cobalt.10155652
    ‚îÇ     ‚Ä¢ NHOSTS: 2
    ‚îÇ     ‚Ä¢ NGPU_PER_HOST: 8
    ‚îÇ     ‚Ä¢ NGPUS (NHOSTS x NGPU_PER_HOST): 16
    ‚îÇ     ‚Ä¢ DIST_LAUNCH: mpirun -n 16 -N 8 --hostfile /var/tmp/cobalt.10155652 -x PATH -x LD_LIBRARY_PATH
    ‚îÇ     ‚Ä¢ Defining alias: launch: aliased to mpirun -n 16 -N 8 --hostfile /var/tmp/cobalt.10155652 -x PATH -x LD_LIBRARY_PATH
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    (thetagpu19) $ mkdir -p venvs/thetaGPU/2023-01-11
    (thetagpu19) $ python3 -m venv venvs/thetaGPU/2023-01-11 --system-site-packages
    (thetagpu19) $ source venvs/thetaGPU/2023-01-11/bin/activate
    (thetagpu19) $ python3 -m pip install -e . --require-virtualenv
    (thetagpu19) $ launch python3 -m ezpz framework=pytorch backend=DDP
    [2023-10-26 12:21:26,716][ezpz.dist][INFO] - Using DDP for distributed training
    [2023-10-26 12:21:26,787][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 13
    [2023-10-26 12:21:26,787][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 14
    [2023-10-26 12:21:26,787][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 8
    [2023-10-26 12:21:26,787][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 12
    [2023-10-26 12:21:26,787][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 6
    [2023-10-26 12:21:26,788][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 9
    [2023-10-26 12:21:26,787][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 10
    [2023-10-26 12:21:26,788][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 15
    [2023-10-26 12:21:26,788][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 11
    [2023-10-26 12:21:26,789][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 7
    [2023-10-26 12:21:26,789][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 3
    [2023-10-26 12:21:26,789][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 1
    [2023-10-26 12:21:26,789][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 4
    [2023-10-26 12:21:26,789][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 5
    [2023-10-26 12:21:26,789][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 2
    [2023-10-26 12:21:26,798][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
    [2023-10-26 12:21:26,811][torch.distributed.distributed_c10d][INFO] - Rank 14: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
    [2023-10-26 12:21:26,812][torch.distributed.distributed_c10d][INFO] - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
    [2023-10-26 12:21:26,814][torch.distributed.distributed_c10d][INFO] - Rank 13: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
    [2023-10-26 12:21:26,815][torch.distributed.distributed_c10d][INFO] - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
    [2023-10-26 12:21:26,816][torch.distributed.distributed_c10d][INFO] - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
    [2023-10-26 12:21:26,817][torch.distributed.distributed_c10d][INFO] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
    [2023-10-26 12:21:26,819][torch.distributed.distributed_c10d][INFO] - Rank 12: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
    [2023-10-26 12:21:26,820][torch.distributed.distributed_c10d][INFO] - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
    [2023-10-26 12:21:26,821][torch.distributed.distributed_c10d][INFO] - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
    [2023-10-26 12:21:26,823][torch.distributed.distributed_c10d][INFO] - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
    [2023-10-26 12:21:26,825][torch.distributed.distributed_c10d][INFO] - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
    [2023-10-26 12:21:26,825][torch.distributed.distributed_c10d][INFO] - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
    [2023-10-26 12:21:26,827][torch.distributed.distributed_c10d][INFO] - Rank 15: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
    [2023-10-26 12:21:26,828][torch.distributed.distributed_c10d][INFO] - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
    [2023-10-26 12:21:26,830][torch.distributed.distributed_c10d][INFO] - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
    [2023-10-26 12:21:26,831][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.
    [2023-10-26 12:21:27,035][ezpz.dist][INFO] - RANK: 0 / 15
    {
      "framework": "pytorch",
      "backend": "DDP",
      "use_wandb": false,
      "seed": null,
      "port": null,
      "ds_config_path": null,
      "wandb_project_name": null,
      "precision": null,
      "ngpus": null
    }
    [2023-10-26 12:21:27,038][__main__][INFO] - Output dir: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/ezpz/outputs/runs/pytorch/DDP/2023-10-26/12-21-25
    [2023-10-26 12:21:27,097][ezpz.dist][INFO] - RANK: 8 / 15
    [2023-10-26 12:21:27,103][ezpz.dist][INFO] - RANK: 6 / 15
    [2023-10-26 12:21:27,104][ezpz.dist][INFO] - RANK: 14 / 15
    [2023-10-26 12:21:27,111][ezpz.dist][INFO] - RANK: 13 / 15
    [2023-10-26 12:21:27,116][ezpz.dist][INFO] - RANK: 1 / 15
    [2023-10-26 12:21:27,126][ezpz.dist][INFO] - RANK: 7 / 15
    [2023-10-26 12:21:27,135][ezpz.dist][INFO] - RANK: 10 / 15
    [2023-10-26 12:21:27,139][ezpz.dist][INFO] - RANK: 12 / 15
    [2023-10-26 12:21:27,141][ezpz.dist][INFO] - RANK: 9 / 15
    [2023-10-26 12:21:27,141][ezpz.dist][INFO] - RANK: 15 / 15
    [2023-10-26 12:21:27,141][ezpz.dist][INFO] - RANK: 11 / 15
    [2023-10-26 12:21:27,141][ezpz.dist][INFO] - RANK: 5 / 15
    [2023-10-26 12:21:27,144][ezpz.dist][INFO] - RANK: 2 / 15
    [2023-10-26 12:21:27,145][ezpz.dist][INFO] - RANK: 4 / 15
    [2023-10-26 12:21:27,145][ezpz.dist][INFO] - RANK: 3 / 15
    16.56s user 30.05s system 706% cpu 6.595s total
    ```

    while this example looked at ThetaGPU, the exact same process will work on any
    of `{ThetaGPU, Polaris, Perlmutter}`.

    </details>

---

::: {.callout-tip icon=false title='[‚ù§Ô∏è‚Äçü©π Status]{style="color: var(--ansi-red);"}' collapse=false style="text-align: left!important; width:100%; background-color: var(--code-bg); border:none!important; border-left: 2px solid var(--ansi-red)!important; opacity:100%; border-radius: 0pt!important;"}

```{python}
#| echo: false
import datetime
from rich import print
now = datetime.datetime.now()
day = now.strftime('%m/%d/%Y')
time = now.strftime('%H:%M:%S')
print(' '.join([
  "[dim italic]Last Updated[/]:",
  f"[#F06292]{day}[/]",
  f"[dim]@[/]",
  f"[#1A8FFF]{time}[/]"
]))
```

<!-- [[![](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fsaforem2.github.io&count_bg=%2300CCFF&title_bg=%23303030&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false)](https://hits.seeyoufarm.com)]{style="text-align:center;"} -->


<p align="center">
<a href="https://hits.seeyoufarm.com"><img align="center" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fsaforem2.github.io%2Fezpz&count_bg=%2300CCFF&title_bg=%23303030&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false"/></a>
</p>

:::

---

<details closed><summary><b>Deprecated:</b></summary>

- Install:
  ```bash
  git clone https://github.com/saforem2/ezpz
  python3 -m pip install -e ezpz
  ```

- Determine available resources:
  ```bash
  [ "$(hostname)==theta*" ] && HOSTFILE="${COBALT_NODEFILE}"  # ThetaGPU @ ALCF
  [ "$(hostname)==x3*" ] && HOSTFILE="${PBS_NODEFILE}"        # Polaris @ ALCF
  [ "$(hostname)==nid*" ] && HOSTFILE="${SLURM_NODELIST}"     # Perlmutter @ NERSC
  NHOSTS=$(wc -l < "${HOSTFILE}")
  NGPU_PER_HOST=$(nvidia-smi -L | wc -l)
  NGPUS="$((${NHOSTS}*${NGPU_PER_HOST}))";
  echo $NHOSTS $NGPU_PER_HOST $NGPUS
  2 4 8
  ```'

- Example `python` script:

  ```python
  """
  ezpz/test.py
  """
  from ezpz import setup_torch, setup_tensorflow


  def test(
      framework: str = 'pytorch',
      backend: str = 'deepspeed',
      port: str = '5432'
  ):
  if framework == 'pytorch':
      _ = setup_torch(
          backend=backend,
          port=port,
      )
  elif framework == 'tensorflow':
      _ = setup_tensorflow()
  else:
      raise ValueError

  if __name__ == '__main__':
      import sys
      try:
          framework = sys.argv[1]
      except IndexError:
              framework = 'pytorch'
      try:
          backend = sys.argv[2]
      except IndexError:
          backend = 'deepspeed'
      try:
          port = sys.argv[3]
      except IndexError:
          port = '5432'
      test(framework=framework, backend=backend, port=port)
  ```

</details>
